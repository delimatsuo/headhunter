{
  "master": {
    "tasks": [
      {
        "id": 54,
        "title": "Setup Together AI Integration and Cloud Infrastructure",
        "description": "Configure Together AI API access, set up GCP project infrastructure in us-central1 region, and establish Firebase/Firestore foundation",
        "details": "Set up GCP project 'headhunter-ai-0088' in us-central1 region. Configure Together AI API key (TOGETHER_API_KEY) and default model (TOGETHER_MODEL_STAGE1=Qwen 2.5 32B Instruct). Enable Firestore, Cloud Storage, Cloud Functions, and Firebase Hosting. Create service accounts with appropriate IAM roles. Set up Cloud Storage buckets for raw-csv, raw-json, and profiles. Configure Firebase Authentication with Google Sign-In restricted to Ella employees.",
        "testStrategy": "Verify API connectivity to Together AI, test Firestore read/write operations, validate Cloud Storage bucket access, confirm Firebase Auth configuration with test user accounts",
        "priority": "high",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Configure GCP Project and Enable Required Services",
            "description": "Set up GCP project 'headhunter-ai-0088' in us-central1 region and enable all required services including Firestore, Cloud Storage, Cloud Functions, Firebase Hosting, and Cloud SQL",
            "dependencies": [],
            "details": "Create GCP project with ID 'headhunter-ai-0088' and set default region to us-central1. Enable the following APIs: Firestore API, Cloud Storage API, Cloud Functions API, Firebase Hosting API, Cloud SQL API, IAM API, and Resource Manager API. Configure billing and set up basic project settings.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "Set up Together AI API Integration and Environment Variables",
            "description": "Configure Together AI API access with proper authentication and set up environment variables for API key and model configuration",
            "dependencies": [
              "54.1"
            ],
            "details": "Configure TOGETHER_API_KEY environment variable for API authentication. Set TOGETHER_MODEL_STAGE1 to 'Qwen 2.5 32B Instruct' as the default model. Test API connectivity and validate that existing Together AI integration patterns in scripts/together_ai_processor.py work with the configured credentials.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "Configure Firebase/Firestore with IAM Roles and Service Accounts",
            "description": "Set up Firebase project, initialize Firestore database, and create service accounts with appropriate IAM roles for secure access",
            "dependencies": [
              "54.1"
            ],
            "details": "Initialize Firebase project linked to GCP project. Set up Firestore in native mode with appropriate security rules. Create service accounts for different components (Cloud Run, Cloud Functions) with minimal required permissions. Configure IAM roles including Firestore User, Storage Object Admin, and Cloud Functions Invoker as needed.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "Create GCS Buckets with Encryption Settings",
            "description": "Set up Google Cloud Storage buckets for raw-csv, raw-json, and profiles with proper encryption and access controls",
            "dependencies": [
              "54.1",
              "54.3"
            ],
            "details": "Create three GCS buckets: 'raw-csv', 'raw-json', and 'profiles' in us-central1 region. Enable default encryption using Google-managed keys. Configure bucket-level IAM policies for secure access. Set up lifecycle policies for data retention and cost optimization. Ensure buckets are properly configured for the resume storage pipeline.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 5,
            "title": "Setup Firebase Authentication with Google Sign-In for Ella Employees",
            "description": "Configure Firebase Authentication with Google Sign-In provider and implement domain restriction for Ella employees only",
            "dependencies": [
              "54.3"
            ],
            "details": "Enable Firebase Authentication and configure Google Sign-In provider. Implement domain restriction to allow only Ella employee email addresses (configure allowed domains). Set up authentication rules and security policies. Create initial admin user accounts for testing. Configure authentication flow and ensure proper integration with the application architecture.",
            "status": "pending",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 55,
        "title": "Implement Cloud Run Candidate Enricher with Together AI",
        "description": "Build Python async processor using Together AI Qwen 2.5 32B for single-pass candidate enrichment with structured JSON output",
        "details": "Create Cloud Run service 'candidate-enricher' using Python 3.10+ with aiohttp. Implement single-pass enrichment calling Together AI chat completions API with PII-minimizing prompts. Generate structured JSON including: personal_details, education_analysis, experience_analysis, technical_assessment, market_insights, cultural_assessment, executive_summary, skill_inference (explicit_skills 100%, inferred_skills with confidence 0-100 and evidence), analysis_confidence [0,1], processing_metadata. Include retry logic, circuit breakers, and rate limiting. Stream results directly to Firestore candidates collection.",
        "testStrategy": "Unit tests for JSON schema validation, integration tests with Together AI API, test error handling and retry mechanisms, validate structured output format matches expected schema",
        "priority": "high",
        "dependencies": [
          54
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Adapt Together AI Processor for Cloud Run with FastAPI",
            "description": "Convert existing together_ai_processor.py to Cloud Run service using FastAPI framework with async request handling",
            "dependencies": [],
            "details": "Create FastAPI application structure with health check endpoint. Adapt existing Together AI client code for Cloud Run environment. Implement async request handlers for candidate enrichment. Configure proper logging and environment variable handling. Set up Docker containerization with Python 3.10+ base image. Include proper error handling for Cloud Run deployment.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "Implement Structured JSON Schema Validation",
            "description": "Create comprehensive JSON schema validation for enriched candidate output using existing validation patterns",
            "dependencies": [
              "55.1"
            ],
            "details": "Define Pydantic models for structured output including personal_details, education_analysis, experience_analysis, technical_assessment, market_insights, cultural_assessment, executive_summary, and processing_metadata. Implement schema validation with detailed error reporting. Add automatic JSON repair mechanisms for common formatting issues. Include validation for required fields and data types.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "Add API Resilience with Retry Logic and Circuit Breakers",
            "description": "Implement robust error handling, retry mechanisms, and circuit breakers for Together AI API calls",
            "dependencies": [
              "55.1"
            ],
            "details": "Add exponential backoff retry logic for API failures. Implement circuit breaker pattern to prevent cascade failures. Add rate limiting to respect Together AI API limits. Include timeout handling and connection pooling. Add comprehensive logging for API interactions and failures. Implement graceful degradation strategies.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "Implement Skill Inference with Confidence Scoring",
            "description": "Build skill inference logic with confidence scoring using patterns from intelligent_skill_processor.py",
            "dependencies": [
              "55.2"
            ],
            "details": "Implement explicit skills extraction with 100% confidence. Add inferred skills detection with confidence scoring (0-100) and evidence tracking. Create skill categorization and normalization logic. Include technical skill assessment and soft skill inference. Add skill gap analysis and market relevance scoring. Ensure structured output matches schema requirements.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 5,
            "title": "Stream Results to Firestore Using Existing Patterns",
            "description": "Implement Firestore streaming using existing firestore_streamer.py patterns for candidate data persistence",
            "dependencies": [
              "55.2",
              "55.4"
            ],
            "details": "Adapt existing firestore_streamer.py for candidate enrichment results. Implement batch writing for efficient Firestore operations. Add document validation before writing. Include error handling for Firestore write failures. Add transaction support for atomic updates. Implement proper indexing strategy for query performance.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 6,
            "title": "Add Processing Metadata and Monitoring",
            "description": "Implement comprehensive processing metadata tracking and monitoring capabilities for the enrichment service",
            "dependencies": [
              "55.3",
              "55.5"
            ],
            "details": "Add processing_metadata including timestamps, API response times, confidence scores, and processing status. Implement health check endpoints for Cloud Run monitoring. Add metrics collection for processing success rates, error rates, and performance. Include structured logging for debugging and audit trails. Add alerting for critical failures and performance degradation.",
            "status": "pending",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 56,
        "title": "Setup Postgres with pgvector for Hybrid Search",
        "description": "Provision Cloud SQL Postgres instance with pgvector extension and implement hybrid search combining vector similarity and PostgreSQL FTS",
        "details": "Create Cloud SQL Postgres instance in us-central1 with pgvector extension enabled. Design schema for candidate_embeddings table with HNSW index for cosine similarity. Implement PostgreSQL Full-Text Search for Portuguese language support. Create hybrid search service that combines pgvector similarity search with FTS, implements score fusion, and supports Together AI reranking on top-K≈200 results to return top-20. Include connection pooling and query optimization.",
        "testStrategy": "Test pgvector installation and HNSW index creation, validate FTS configuration for Portuguese, benchmark hybrid search performance, test score fusion algorithms",
        "priority": "high",
        "dependencies": [
          54
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Provision Cloud SQL Postgres Instance",
            "description": "Create and configure Cloud SQL Postgres instance in us-central1 region with appropriate machine type and storage settings",
            "dependencies": [],
            "details": "Provision Cloud SQL Postgres instance in us-central1 with sufficient resources for vector operations. Configure network settings, backup policies, and maintenance windows. Enable necessary flags for pgvector extension support.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "Install pgvector Extension and Create Schema",
            "description": "Install pgvector extension on the Postgres instance and execute schema creation scripts",
            "dependencies": [
              "56.1"
            ],
            "details": "Install pgvector extension on the provisioned Postgres instance. Execute scripts/pgvector_schema.sql to create the database schema. Verify extension installation and schema creation success.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "Design and Create candidate_embeddings Table with HNSW Index",
            "description": "Create the candidate_embeddings table with proper vector columns and HNSW index for cosine similarity",
            "dependencies": [
              "56.2"
            ],
            "details": "Design candidate_embeddings table schema with vector columns for embeddings. Create HNSW index optimized for cosine similarity searches. Configure index parameters for optimal performance with expected data volume.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "Implement PostgreSQL Full-Text Search for Portuguese",
            "description": "Configure PostgreSQL FTS with Portuguese language support and create necessary text search configurations",
            "dependencies": [
              "56.2"
            ],
            "details": "Configure PostgreSQL Full-Text Search with Portuguese language dictionary and stemming. Create text search configurations, indexes, and functions to support Portuguese text search on candidate data.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 5,
            "title": "Create Hybrid Search Service",
            "description": "Implement Python service that combines pgvector similarity search with PostgreSQL FTS",
            "dependencies": [
              "56.3",
              "56.4"
            ],
            "details": "Build Python service that performs both vector similarity search using pgvector and full-text search using PostgreSQL FTS. Implement query logic to execute both search types and combine results effectively.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 6,
            "title": "Implement Score Fusion and Together AI Reranking",
            "description": "Develop score fusion algorithm and integrate Together AI reranking for top-K results",
            "dependencies": [
              "56.5"
            ],
            "details": "Implement score fusion algorithm to combine vector similarity and FTS scores. Integrate Together AI reranking on top-K≈200 results to return top-20. Optimize fusion weights and reranking parameters for best results.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 7,
            "title": "Add Connection Pooling and Query Optimization",
            "description": "Implement database connection pooling and optimize queries for performance",
            "dependencies": [
              "56.6"
            ],
            "details": "Add connection pooling using appropriate Python library (e.g., asyncpg pool). Optimize database queries for hybrid search performance. Implement query caching where appropriate and add monitoring for query performance metrics.",
            "status": "pending",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 57,
        "title": "Implement Vertex AI Embeddings Generation Service",
        "description": "Create embeddings generation service using Vertex AI text-embedding-004 with pluggable provider architecture for future migration",
        "details": "Implement VectorSearchService using Vertex AI text-embedding-004 (768-dim, cosine) in us-central1. Create pluggable provider architecture with environment variable EMBEDDING_PROVIDER supporting vertex|together|local. Generate embeddings from enriched candidate profiles and store in candidate_embeddings table. Implement batch processing for efficient embedding generation. Include fallback mechanisms and error handling for API failures.",
        "testStrategy": "Test embedding generation with sample profiles, validate 768-dimension output, test provider switching mechanism, benchmark embedding generation performance and cost",
        "priority": "medium",
        "dependencies": [
          56
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement VectorSearchService with Vertex AI Integration",
            "description": "Create the core VectorSearchService class with Vertex AI text-embedding-004 integration, configured for us-central1 region and 768-dimensional embeddings with cosine similarity",
            "dependencies": [],
            "details": "Implement VectorSearchService class with Vertex AI client initialization, text-embedding-004 model configuration (768-dim, cosine), region setup for us-central1, and basic embedding generation methods. Include proper authentication and client configuration.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "Create Pluggable Provider Architecture",
            "description": "Design and implement the provider abstraction layer with environment variable switching between vertex, together, and local embedding providers",
            "dependencies": [
              "57.1"
            ],
            "details": "Create abstract EmbeddingProvider interface and concrete implementations for VertexAIProvider, TogetherProvider, and LocalProvider. Implement provider factory with EMBEDDING_PROVIDER environment variable switching. Ensure consistent API across all providers.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "Implement Batch Processing System",
            "description": "Build efficient batch processing capabilities for embedding generation to optimize API calls and reduce costs",
            "dependencies": [
              "57.2"
            ],
            "details": "Implement batch processing logic with configurable batch sizes, queue management for embedding requests, and efficient batching strategies. Include rate limiting and cost optimization features for API calls.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "Integrate pgvector Storage System",
            "description": "Implement database integration to store generated embeddings in the candidate_embeddings table using pgvector",
            "dependencies": [
              "57.3"
            ],
            "details": "Create database schema for candidate_embeddings table with pgvector support, implement CRUD operations for embedding storage and retrieval, add indexing for efficient similarity search, and ensure proper data persistence.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 5,
            "title": "Add Fallback Mechanisms and Error Handling",
            "description": "Implement comprehensive error handling, retry logic, and fallback mechanisms for API failures and service disruptions",
            "dependencies": [
              "57.4"
            ],
            "details": "Add retry logic with exponential backoff, circuit breaker patterns for API failures, fallback provider switching, comprehensive error logging and monitoring, and graceful degradation strategies for service reliability.",
            "status": "pending",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 58,
        "title": "Build Pub/Sub Orchestration and Batch Processing Pipeline",
        "description": "Implement Pub/Sub messaging system for candidate processing orchestration with Cloud Scheduler for batch operations",
        "details": "Create Pub/Sub topic 'candidate-process-requests' for processing coordination. Implement message handlers that trigger candidate enrichment workflow: GCS upload → Pub/Sub message → Cloud Run enricher → Firestore → embedding generation. Set up Cloud Scheduler for batch processing of initial 29k candidates and nightly reprocessing. Implement idempotency using candidate_id for upserts across Firestore and pgvector. Include dead letter queues and retry policies.",
        "testStrategy": "Test message flow from GCS trigger to completion, validate idempotency with duplicate messages, test batch processing with sample dataset, verify scheduler configuration",
        "priority": "medium",
        "dependencies": [
          55
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 59,
        "title": "Implement JSON Validation and Error Handling Pipeline",
        "description": "Build robust JSON parsing, schema validation, and error recovery system with repair mechanisms and quarantine handling",
        "details": "Implement comprehensive JSON validation against defined schema for candidate profiles. Add automatic JSON repair for common formatting issues (strip code fences, fix malformed JSON). Create quarantine system for profiles that fail validation after repair attempts. Target <1% repair/quarantine rate and ≥95% valid JSON parse rate. Include retry logic with repair prompts for malformed outputs. Log all validation failures and repairs for monitoring.",
        "testStrategy": "Test with malformed JSON samples, validate repair mechanisms, test quarantine workflow, measure validation success rates, test schema compliance",
        "priority": "high",
        "dependencies": [
          55
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 60,
        "title": "Develop Search API with Together AI Reranking",
        "description": "Create unified search API that combines pgvector similarity, FTS, and Together AI reranking with explainability evidence",
        "details": "Implement search API that performs: 1) Hybrid recall using pgvector HNSW cosine similarity + PostgreSQL FTS for Portuguese, 2) Score fusion of vector and text search results, 3) Together AI reranking on top-K≈200 to return top-20 results, 4) Generate explainability evidence per skill match. Target p95 ≤ 1.2s total latency and rerank ≤ 350ms. Include composite scoring combining skill_match, confidence, vector_similarity, and experience. Store and return 'Why match' bullets for UI display.",
        "testStrategy": "Benchmark search latency with various query types, test reranking accuracy, validate explainability evidence generation, test with English and Portuguese job descriptions",
        "priority": "high",
        "dependencies": [
          56,
          57
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 61,
        "title": "Build Firebase Cloud Functions API Layer",
        "description": "Implement Node.js/TypeScript Cloud Functions for CRUD operations, file upload pipeline, and search endpoints",
        "details": "Create Cloud Functions v2 for: candidates-crud.ts (CRUD operations), jobs-crud.ts (job management), file-upload-pipeline.ts (GCS integration), vector-search.ts (search endpoints), generate-embeddings.ts (embedding coordination). Implement Firebase Authentication integration with allowed_users collection for access control. Add callable functions: skillAwareSearch, getCandidateSkillAssessment, addAllowedUser, removeAllowedUser, listAllowedUsers, setAllowedUserRole. Include proper error handling and security rules.",
        "testStrategy": "Test all CRUD operations, validate authentication and authorization, test file upload workflow, verify search endpoint integration, test admin functions",
        "priority": "medium",
        "dependencies": [
          60
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 62,
        "title": "Implement Resume Storage with GCS and Signed URLs",
        "description": "Set up encrypted resume storage in Google Cloud Storage with signed URL generation for secure access",
        "details": "Configure GCS buckets for encrypted resume storage with appropriate IAM policies. Implement signed URL generation for secure, time-limited access to resume files. Store LinkedIn URLs extracted from CSV or resume text using regex patterns. Track resume_updated_at for freshness indicators. Implement upload pipeline that processes resumes and stores metadata in Firestore with references to GCS objects. No automated LinkedIn scraping in MVP.",
        "testStrategy": "Test file encryption and storage, validate signed URL generation and expiration, test LinkedIn URL extraction, verify secure access controls",
        "priority": "medium",
        "dependencies": [
          54
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 63,
        "title": "Build React Frontend with Semantic Search Interface",
        "description": "Develop React application with job description input, ranked candidate results, and explainability features",
        "details": "Create React SPA hosted on Firebase Hosting with: 1) JD input interface supporting EN/PT-BR, 2) Search results displaying top-20 candidates with minimal row content (name, current role, years/level, composite score, freshness badge, LinkedIn link), 3) Candidate detail page with full skill map, inferred skills with confidence, evidence tooltips, career timeline, 4) 'Why they're a match' bullets display, 5) Pre-interview analysis on-demand. Implement Firebase Authentication integration and role-based UI elements.",
        "testStrategy": "Test search interface with various job descriptions, validate result display and ranking, test candidate detail views, verify authentication flow, test responsive design",
        "priority": "medium",
        "dependencies": [
          61
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 64,
        "title": "Implement Admin Interface and User Management",
        "description": "Build admin-only interface for user management and system monitoring with role-based access control",
        "details": "Create admin-only React components for: 1) User management interface to add/remove allowed_users, 2) Role assignment (admin/recruiter/viewer), 3) System health monitoring (Firestore counts, embedding stats), 4) Processing register for compliance. Implement role-based guards using Firebase Auth custom claims. Add audit logging for sensitive operations. Include allowed_users collection management with email domain validation for Ella employees.",
        "testStrategy": "Test admin role restrictions, validate user management operations, test system monitoring displays, verify audit logging functionality",
        "priority": "low",
        "dependencies": [
          61
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 65,
        "title": "Implement Compliance and Data Privacy Features",
        "description": "Add compliance fields, processing register, and data privacy controls to meet regulatory requirements",
        "details": "Implement compliance fields in candidate profiles: legal_basis (required), consent_record (optional). Create exportable processing register for audit purposes. Add PII minimization in Together AI prompts. Implement data retention policies and secure deletion capabilities. Add audit logging for all data access and processing events. Ensure Firestore security rules enforce proper access controls. Include data subject rights management (access, rectification, erasure).",
        "testStrategy": "Validate compliance field presence in all profiles, test processing register export, verify PII minimization in prompts, test audit logging completeness, validate security rule enforcement",
        "priority": "medium",
        "dependencies": [
          59,
          62
        ],
        "status": "pending",
        "subtasks": []
      }
    ],
    "metadata": {
      "created": "2025-09-05T18:18:48.859Z",
      "updated": "2025-09-13T19:24:01.303Z",
      "description": "Tasks for master context"
    }
  }
}